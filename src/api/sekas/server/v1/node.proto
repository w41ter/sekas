// Copyright 2023-present The Sekas Authors.
// Copyright 2022 The Engula Authors.
//
// Licensed under the Apache License, Version 2.0 (the "License");
// you may not use this file except in compliance with the License.
// You may obtain a copy of the License at
//
// http://www.apache.org/licenses/LICENSE-2.0
//
// Unless required by applicable law or agreed to in writing, software
// distributed under the License is distributed on an "AS IS" BASIS,
// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
// See the License for the specific language governing permissions and
// limitations under the License.

syntax = "proto3";

package sekas.server.v1;

import "sekas/server/v1/error.proto";
import "sekas/server/v1/metadata.proto";
import "sekas/server/v1/types.proto";
import "sekas/server/v1/write.proto";
import "google/protobuf/field_mask.proto";

service Node {
    rpc Group(GroupRequest) returns (stream GroupResponse) {}
    // A set methods to manipulate node.
    rpc Admin(NodeAdminRequest) returns (NodeAdminResponse) {}
    // A set methods about shard moving.
    rpc MoveShard(MoveShardRequest) returns (MoveShardResponse) {}
}

message GroupRequest {
    uint64 group_id = 1;
    uint64 epoch = 2;
    GroupRequestUnion request = 3;
}

message GroupResponse {
    GroupResponseUnion response = 1;
    Error error = 2;
}

message GroupRequestUnion {
    oneof request {
        // Single operation.
        ShardGetRequest get = 1;
        ShardScanRequest scan = 2;
        ShardWriteRequest write = 3;

        // Watch a key's updation.
        WatchKeyRequest watch_key = 4;

        // Txn releated operation.
        WriteIntentRequest write_intent = 11;
        CommitIntentRequest commit_intent = 12;
        ClearIntentRequest clear_intent = 13;

        // Add a new shard to an existing group.
        CreateShardRequest create_shard = 20;

        // Change replicas of an existing group.
        ChangeReplicasRequest change_replicas = 21;

        // Issue a moving shard request. This request need to send to the dest group.
        AcceptShardRequest accept_shard = 22;

        // Transfer leadership to another replicas. This request is executed as a notice, so
        // the response doesn't reflect the actual execution result of transferring.
        TransferRequest transfer = 23;

        // MoveReplicas delegates the replicas moving to group leader.
        //
        // Response once the group leader accepts the moving replicas request. When there exists
        // some conflicts, such as group is in joint, `Error::AlreadyExists` is returned.
        MoveReplicasRequest move_replicas = 24;

        // Split a shard.
        SplitShardRequest split_shard = 25;

        // Merge two shards.
        MergeShardRequest merge_shard = 26;
    }
}

message GroupResponseUnion {
    oneof response {
        ShardGetResponse get = 1;
        ShardScanResponse scan = 2;
        ShardWriteResponse write = 3;
        WatchKeyResponse watch_key = 4;

        WriteIntentResponse write_intent = 10;
        CommitIntentResponse commit_intent = 11;
        ClearIntentResponse clear_intent = 12;

        CreateShardResponse create_shard = 20;
        ChangeReplicasResponse change_replicas = 21;
        AcceptShardResponse accept_shard = 22;
        TransferResponse transfer = 23;
        MoveReplicasResponse move_replicas = 24;
        SplitShardResponse split_shard = 25;
        MergeShardResponse merge_shard = 26;
    }
}

// The batch writes to a shard which ensure atomic writes.
message ShardWriteRequest {
    uint64 shard_id = 1;
    repeated DeleteRequest deletes = 2;
    repeated PutRequest puts = 3;
}

// The response of batch writes to a shard.
message ShardWriteResponse {
    repeated WriteResponse deletes = 1;
    repeated WriteResponse puts = 2;
}

message ShardGetRequest {
    uint64 shard_id = 1;
    uint64 start_version = 2;
    bytes user_key = 3;
}

message ShardGetResponse {
    optional Value value = 1;
}

message ShardScanRequest {
    // The id of target shard.
    uint64 shard_id = 1;
    // The start version of scan request.
    uint64 start_version = 2;
    // The maxminum key-values pairs to fetch, 0 means no limit.
    uint64 limit = 3;
    // The maxminum key-value bytes to fetch, 0 means no limit.
    uint64 limit_bytes = 4;
    // Shoud include start key in result? not support in prefix scan.
    bool exclude_start_key = 5;
    // Shoud include end key in result? not support in prefix scan.
    bool exclude_end_key = 6;
    // Scan with prefix, if set then `start_key` and `end_key` will be ignored.
    //
    // The prefix only works with range shard, the behaviour of hash shard is undefined.
    optional bytes prefix = 7;
    // The start key of the range, scan all keys if the start key is not specified.
    optional bytes start_key = 8;
    // The end key of the range, scan all keys [start_key, inf) if the end_key is not specified.
    optional bytes end_key = 9;
    // Include all data (tombstone) as return values.
    bool include_raw_data = 10;
    // Ignore txn intents rather than resolve it.
    bool ignore_txn_intent = 11;
    // Allow scan an moving shard, without forwarding.
    bool allow_scan_moving_shard = 12;
}

message ShardScanResponse {
    // The value set.
    repeated ValueSet data = 1;
    // Has more data to scan?
    bool has_more = 2;
}

message WriteIntentRequest {
    uint64 shard_id = 1;
    uint64 start_version = 2;

    // The write request.
    oneof write {
        DeleteRequest delete = 3;
        PutRequest put = 4;
    }
}

message WriteIntentResponse {
    WriteResponse write = 1;
}

message CommitIntentRequest {
    uint64 shard_id = 1;
    uint64 start_version = 2;
    uint64 commit_version = 3;
    bytes user_key = 4;
}

message CommitIntentResponse {}

message ClearIntentRequest {
    uint64 shard_id = 1;
    uint64 start_version = 2;
    bytes user_key = 3;
}

message ClearIntentResponse {}

message NodeAdminRequest {
    oneof request {
        GetRootRequest get_root = 1;
        CreateReplicaRequest create_replica = 2;

        // RemoveReplica allows shuts down and deletes an orphan replica from the
        // specified node.
        //
        // It is only executed when the user specifies a newer `GroupDesc` and the
        // replica no longer belongs to the group.
        RemoveReplicaRequest remove_replica = 3;
        HeartbeatRequest heartbeat = 4;
    }
}

message NodeAdminResponse {
    oneof response {
        GetRootResponse get_root = 1;
        CreateReplicaResponse create_replica = 2;
        RemoveReplicaResponse remove_replica = 3;
        HeartbeatResponse heartbeat = 4;
    }
}

message GetRootRequest {}

message GetRootResponse { RootDesc root = 1; }

message CreateReplicaRequest {
    uint64 replica_id = 1;
    GroupDesc group = 2;
}

message CreateReplicaResponse {}

message RemoveReplicaRequest {
    uint64 replica_id = 1;
    GroupDesc group = 2;
}

message RemoveReplicaResponse {}

message CreateShardRequest { ShardDesc shard = 1; }

message CreateShardResponse {}

message ChangeReplicasRequest { ChangeReplicas change_replicas = 1; }

message ChangeReplicasResponse {}

message ChangeReplicas { repeated ChangeReplica changes = 1; }

message ChangeReplica {
    ChangeReplicaType change_type = 1;

    uint64 replica_id = 2;
    uint64 node_id = 3;
}

enum ChangeReplicaType {
    ADD = 0;
    REMOVE = 1;
    ADD_LEARNER = 2;
}

message AcceptShardRequest {
    // The source group of this moving shard.
    uint64 src_group_id = 1;
    // The epoch of source group when issuing this moving shard request.
    uint64 src_group_epoch = 2;
    // The descriptor of moving shard.
    ShardDesc shard_desc = 3;
}

message AcceptShardResponse {}

message TransferRequest {
    uint64 transferee = 1;
}

message TransferResponse {}

message HeartbeatRequest {
    uint64 timestamp = 1;
    repeated PiggybackRequest piggybacks = 2;
}

message HeartbeatResponse {
    uint64 timestamp = 1;
    // The epoch of root group which contained in node's `RootDesc`.
    uint64 root_epoch = 2;
    repeated PiggybackResponse piggybacks = 3;
}

message PiggybackRequest {
    oneof info {
        SyncRootRequest sync_root = 1;
        CollectStatsRequest collect_stats = 2;
        CollectGroupDetailRequest collect_group_detail = 3;
        CollectScheduleStateRequest collect_schedule_state = 4;
        CollectMovingShardStateRequest collect_moving_shard_state = 5;
    }
}

message PiggybackResponse {
    oneof info {
        SyncRootResponse sync_root = 1;
        CollectStatsResponse collect_stats = 2;
        CollectGroupDetailResponse collect_group_detail = 3;
        CollectScheduleStateResponse collect_schedule_state = 4;
        CollectMovingShardStateResponse collect_moving_shard_state = 5;
    }
}

message SyncRootRequest { RootDesc root = 1; }

message SyncRootResponse {}

message CollectStatsRequest { google.protobuf.FieldMask field_mask = 1; }

message CollectStatsResponse {
    NodeStats node_stats = 1;
    repeated GroupStats group_stats = 2;
    repeated ReplicaStats replica_stats = 3;
}

message NodeStats {
    uint64 available_space = 1;
    uint32 group_count = 2;
    uint32 leader_count = 3;
    // The replicas field in `GroupDesc` is empty.
    uint64 orphan_replica_count = 4;
    float read_qps = 5;
    float write_qps = 6;
}

// The stats of an shard.
message ShardStats {
    // The id of the shard
    uint64 shard_id = 1;
    // The table id of the shard
    uint64 table_id = 2;
    // The size of the shard
    uint64 shard_size = 3;
}

message GroupStats {
    uint64 group_id = 1;
    uint64 shard_count = 2;
    float read_qps = 3;
    float write_qps = 4;
    repeated ShardStats shard_stats = 5;
}

message ReplicaStats {
    uint64 replica_id = 1;
    uint64 group_id = 2;
    float read_qps = 3;
    float write_qps = 4;
}

message CollectGroupDetailRequest {
    // The ID list of the group that needs to get the status, if it is empty, get
    // all the groups on the target machine.
    repeated uint64 groups = 1;
}

message CollectGroupDetailResponse {
    repeated ReplicaState replica_states = 1;
    // If a replica is the leader of group, it also needs to be responsible for
    // filling in the `GroupDesc`.
    repeated GroupDesc group_descs = 2;
}

message CollectScheduleStateRequest {}

message CollectScheduleStateResponse {
    repeated ScheduleState schedule_states = 1;
}

message CollectMovingShardStateRequest { uint64 group = 1; }

message CollectMovingShardStateResponse {
    enum State {
        NONE = 0;
        PREPARE = 1;
        MOVING = 2;
        MOVED = 3;
    }

    State state = 1;
    MoveShardDesc desc = 2;
}

message MoveReplicasRequest {
    repeated ReplicaDesc incoming_voters = 1;
    repeated ReplicaDesc outgoing_voters = 2;
}

message MoveReplicasResponse {
    ScheduleState schedule_state = 1;
}

message MoveShardRequest {
    oneof request {
        ForwardRequest forward = 1;
        AcquireShardRequest acquire_shard = 2;
        MoveOutRequest move_out = 3;
    }
}

message MoveShardResponse {
    oneof response {
        ForwardResponse forward = 1;
        AcquireShardResponse acquire_shard = 2;
        MoveOutResponse move_out = 3;
    }
}

message ForwardRequest {
    uint64 group_id = 1;
    uint64 shard_id = 2;
    repeated ValueSet forward_data = 3;
    GroupRequestUnion request = 4;
}

message ForwardResponse {
    GroupResponseUnion response = 1;
}

message AcquireShardRequest {
    MoveShardDesc desc = 1;
}

message AcquireShardResponse {}

message MoveOutRequest {
    MoveShardDesc desc = 1;
}

message MoveOutResponse {}

// The request to issue a watch stream.
message WatchKeyRequest {
    // The target shard id;
    uint64 shard_id = 1;
    // The target group id.
    uint64 group_id = 2;
    // The key to watch.
    bytes key = 3;
    // The current version of the key to watch.
    uint64 version = 4;
}

// The watch response.
message WatchKeyResponse {
    enum WatchResult {
        SHARD_MOVED = 0;
        VALUE_UPDATED = 1;
    }

    WatchResult result = 1;
    optional Value value = 2;
}

// The split shard request.
message SplitShardRequest {
    // The id of the shard to split.
    uint64 old_shard_id = 1;
    // The id of the new shard.
    uint64 new_shard_id = 2;
    // The recommend split key, if not specified, read split keys from table properties.
    optional bytes split_key = 3;
}

// The split shard response.
message SplitShardResponse {}

// The merge shard request.
message MergeShardRequest {
    // The id of the left shard.
    uint64 left_shard_id = 1;
    // The id of the right shard.
    uint64 right_shard_id = 2;
}

// The merge shard response.
message MergeShardResponse {}
